{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc11f08a",
   "metadata": {},
   "source": [
    "# InSyBio - Data for Harry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25df2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dd79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def Preprocessing(params, X, y): # FULL\n",
    "    # Normalize=1\n",
    "    normalize = params['normalization']\n",
    "    if (normalize == 'Yes'):\n",
    "        # Subset of columns to transform\n",
    "        already_normalized = (X.max() == 1) & (X.min() == 0)\n",
    "        set1 = set(X.columns)\n",
    "        set2 = set(already_normalized)\n",
    "        cols = list(set1 - set2)\n",
    "        X_normalized = X\n",
    "        X_normalized.loc[:,cols] = preprocessing.MinMaxScaler(feature_range=(0,1)).fit_transform(X_normalized[cols])\n",
    "    else:\n",
    "        X_normalized = X\n",
    "        print('No normalization.')\n",
    "\n",
    "    # Imputation\n",
    "    imputation_method = params['imputation_method']\n",
    "    #print(imputation_method)\n",
    "    X_imputed = X_normalized\n",
    "    if (imputation_method == 'zero'):\n",
    "        X_imputed = X\n",
    "        X_imputed.update(X_imputed.fillna(0))\n",
    "    elif (imputation_method == 'simple'):\n",
    "        imputer = SimpleImputer(strategy='mean') # 'mean' 'most_frequent'\n",
    "\n",
    "        X_imputed = imputer.fit_transform(X)\n",
    "        X_imputed = pd.DataFrame(X_imputed, columns = imputer.get_feature_names_out()) \n",
    "    elif (imputation_method == 'knn'):\n",
    "       # Define KNN imputer and fill missing values\n",
    "        imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "        X_imputed = imputer.fit_transform(X)\n",
    "        X_imputed = pd.DataFrame(X_imputed, columns = imputer.get_feature_names_out())\n",
    "    elif (imputation_method == 'mice'):\n",
    "        # Define MICE Imputer and fill missing values\n",
    "        imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), max_value = 1, min_value=0, n_nearest_features=None, imputation_order='ascending', max_iter=50)\n",
    "\n",
    "        X_imputed = imputer.fit_transform(X)\n",
    "        X_imputed = pd.DataFrame(X_imputed, columns=imputer.get_feature_names_out())\n",
    "    else:\n",
    "        X_imputed = X\n",
    "        print('No imputation.')\n",
    "                \n",
    "    # Instance selection\n",
    "    instance_selection = params['instance_selection']\n",
    "    #print(instance_selection)\n",
    "    if (imputation_method != 'None'):\n",
    "        if (instance_selection == 'local'):\n",
    "            lof = LocalOutlierFactor()\n",
    "            yhat = lof.fit_predict(X_imputed)\n",
    "\n",
    "            # select all rows that are not outliers\n",
    "            mask = pd.Series(yhat != -1)\n",
    "\n",
    "            X_imputed = X_imputed[mask.values]\n",
    "            y_imputed = y[mask.values]\n",
    "        elif (instance_selection == 'isolation_forest'):\n",
    "            clf = IsolationForest(n_estimators=10, warm_start=True)\n",
    "            yhat = clf.fit_predict(X_imputed)  # fit 10 trees  \n",
    "            #clf.set_params(n_estimators=20)  # add 10 more trees  \n",
    "            #clf.fit(X)  # fit the added trees  \n",
    "\n",
    "            # select all rows that are not outliers\n",
    "            mask = pd.Series(yhat != -1)\n",
    "\n",
    "            X_imputed = X_imputed[mask.values]\n",
    "            y_imputed = y[mask.values]\n",
    "        else:\n",
    "            print('No instance selection.')\n",
    "            y_imputed = y\n",
    "    else:\n",
    "            print('No instance selection without imputation.')\n",
    "            y_imputed = y\n",
    "        \n",
    "    # Feature selection\n",
    "    feature_selection = params['feature_selection']\n",
    "    #print(feature_selection)\n",
    "    if (feature_selection == 'best'):       \n",
    "        X_new = SelectKBest(f_classif, k=params['k']).fit(X_imputed, y_imputed)\n",
    "        full_filtered_features = X_new.get_feature_names_out()\n",
    "        print(full_filtered_features)\n",
    "        X_imputed = X_imputed[full_filtered_features]\n",
    "    else:\n",
    "        print('No feature selection.')\n",
    "        \n",
    "    return X_imputed, y_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735dac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:\\\\Users\\\\harry\\\\Desktop\\\\train_ds.csv\")\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\harry\\\\Desktop\\\\test_dataset\\\\TEST_DATASET_PROCESSED.csv\")\n",
    "#df_test=df_test.drop(['uidA', 'uidB'])\n",
    "\n",
    "features_all = ['BP_similarity', 'MF_similarity', 'CC_similarity',  # drop homologous features\n",
    "            'Exists in MINT?', 'Exists in DIP?', 'Exists in APID?',\n",
    "            'Exists in BIOGRID?', 'Sequence_similarity', 'pfam_interaction',\n",
    "            'MW dif', 'Aromaticity dif', 'Instability dif', 'helix_fraction_dif', 'turn_fraction_dif',\n",
    "            'sheet_fraction_dif', 'cys_reduced_dif', 'gravy_dif', 'ph7_charge_dif', 'A %', 'L %', 'F %', 'I %', 'M %', 'V %',\n",
    "            'S %', 'P %', 'T %', 'Y %', 'H %', 'Q %', 'N %', 'K %', 'D %', 'E %', 'C %', 'W %', 'R %', 'G %', \n",
    "            'GSE227375_spearman', 'GSE228702_spearman']\n",
    "\n",
    "features_not_exists = ['BP_similarity', 'MF_similarity', 'CC_similarity',\n",
    "            'Sequence_similarity', 'pfam_interaction',\n",
    "            'MW dif', 'Aromaticity dif', 'Instability dif', 'helix_fraction_dif', 'turn_fraction_dif',\n",
    "            'sheet_fraction_dif', 'cys_reduced_dif', 'gravy_dif', 'ph7_charge_dif',  'A %', 'L %', 'F %', 'I %', 'M %', 'V %',\n",
    "            'S %', 'P %', 'T %', 'Y %', 'H %', 'Q %', 'N %', 'K %', 'D %', 'E %', 'C %', 'W %', 'R %', 'G %', \n",
    "            'GSE227375_spearman', 'GSE228702_spearman']\n",
    "\n",
    "X_train_all = df_train[features_all]\n",
    "y_train_all = df_train['PPI_type']\n",
    "\n",
    "X_train_not_exists = df_train[features_not_exists]\n",
    "y_train_not_exists = df_train['PPI_type']\n",
    "\n",
    "X_test_all = df_test[features_all]\n",
    "y_test_all = df_test['PPI_type']\n",
    "\n",
    "X_test_not_exists = df_test[features_not_exists]\n",
    "y_test_not_exists = df_test['PPI_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a67f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP_similarity 5.320367398649628e-116\n",
      "MF_similarity 5.320367398649628e-116\n",
      "CC_similarity 5.320367398649628e-116\n",
      "Exists in MINT? 0.007107157790916954\n",
      "Exists in APID? 7.285269393806746e-12\n",
      "Exists in BIOGRID? 3.313452490087753e-75\n",
      "pfam_interaction 9.8095001936916e-78\n",
      "MW dif 0.0\n",
      "Aromaticity dif 0.0\n",
      "Instability dif 0.0\n",
      "helix_fraction_dif 0.0\n",
      "turn_fraction_dif 3.1595208300568364e-141\n",
      "sheet_fraction_dif 0.0\n",
      "cys_reduced_dif 0.0\n",
      "gravy_dif 0.0\n",
      "ph7_charge_dif 0.0\n",
      "A % 0.0\n",
      "L % 0.0\n",
      "F % 0.0\n",
      "I % 0.0\n",
      "M % 0.0\n",
      "V % 0.0\n",
      "S % 0.0\n",
      "P % 0.0\n",
      "T % 0.0\n",
      "Y % 0.0\n",
      "H % 0.0\n",
      "Q % 0.0\n",
      "N % 1.8357566280008424e-145\n",
      "K % 0.0\n",
      "D % 0.0\n",
      "E % 0.0\n",
      "C % 0.0\n",
      "W % 0.0\n",
      "R % 0.0\n",
      "G % 0.0\n",
      "GSE227375_spearman 0.0\n",
      "GSE228702_spearman 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in features_all:\n",
    "    value = stats.ks_2samp(X_train_all[i], X_test_all[i])\n",
    "    if (value[1] <= 0.05):\n",
    "        print(i, value[1]) # Same distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd037a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'imputation_method': 'simple',\n",
    "          'normalization': 'Yes',\n",
    "          'feature_selection': 'None',\n",
    "          'k': 0,\n",
    "          'instance_selection': 'None',\n",
    "          'ml_algorithm': 'xgboost'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca25db22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_26732\\1266884227.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_normalized.loc[:,cols] = preprocessing.MinMaxScaler(feature_range=(0,1)).fit_transform(X_normalized[cols])\n",
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_26732\\1266884227.py:15: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_normalized.loc[:,cols] = preprocessing.MinMaxScaler(feature_range=(0,1)).fit_transform(X_normalized[cols])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instance selection.\n",
      "No feature selection.\n",
      "\\ Metrics for Training Set:\n",
      "Accuracy: 0.8814064362336115\n",
      "Specificity: 1.0\n",
      "Recall: 0.6442193087008343\n",
      "F1 Score: 0.7836172526277637\n",
      "F2 Score: 0.693571153599384\n",
      "ROC-AUC Score: 0.8221096543504172\n",
      "\\ Metrics for Test Set:\n",
      "Accuracy: 0.7562217416945154\n",
      "Specificity: 0.9863164517143755\n",
      "Recall: 0.5261813035616008\n",
      "F1 Score: 0.6834137499680886\n",
      "F2 Score: 0.5795124907996708\n",
      "ROC-AUC Score: 0.7562488776379882\n"
     ]
    }
   ],
   "source": [
    "X_imputed_train, y_imputed_train = Preprocessing(params, X_train_all, y_train_all)\n",
    "    \n",
    "clf_FULL = xgb.XGBClassifier(n_estimators=50, objective='binary:logistic', random_state=1, \n",
    "                             tree_method='hist', eta=0.3, gamma=0.4, max_depth=10)\n",
    "clf_FULL.fit(X_imputed_train, y_imputed_train)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train_all, clf_FULL.predict(X_train_all))\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test_all, clf_FULL.predict(X_test_all))\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix_test.ravel()\n",
    "specificity_test = tn / (tn + fp)\n",
    "print(\"\\ Metrics for Training Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train_all, clf_FULL.predict(X_train_all)))\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Recall:\", recall_score(y_train_all, clf_FULL.predict(X_train_all)))\n",
    "print(\"F1 Score:\", f1_score(y_train_all, clf_FULL.predict(X_train_all)))\n",
    "print(\"F2 Score:\", fbeta_score(y_train_all, clf_FULL.predict(X_train_all), beta=2))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_train_all, clf_FULL.predict(X_train_all)))\n",
    "print(\"\\ Metrics for Test Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_all, clf_FULL.predict(X_test_all)))\n",
    "print(\"Specificity:\", specificity_test)\n",
    "print(\"Recall:\", recall_score(y_test_all, clf_FULL.predict(X_test_all)))\n",
    "print(\"F1 Score:\", f1_score(y_test_all, clf_FULL.predict(X_test_all)))\n",
    "print(\"F2 Score:\", fbeta_score(y_test_all, clf_FULL.predict(X_test_all), beta=2))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test_all, clf_FULL.predict(X_test_all)))\n",
    "\n",
    "clf_FULL.save_model('train_full_features.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e56f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.3s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.3s\n",
      "CV Mean Metrics:\n",
      "fit_time: 0.30356712341308595\n",
      "score_time: 0.028536319732666016\n",
      "test_accuracy: 0.9707994098898671\n",
      "test_specificity: 0.9657364960909739\n",
      "test_precision: 0.93483821336077\n",
      "test_recall: 0.9809345594525235\n",
      "test_f1: 0.9572793806278668\n",
      "test_f2: 0.9713200805379005\n",
      "test_roc_auc: 0.9733355277717486\n",
      "\n",
      "CV Standard Deviations:\n",
      "fit_time: 0.03390751361265506\n",
      "score_time: 0.003691225183589648\n",
      "test_accuracy: 0.003969723721104781\n",
      "test_specificity: 0.006119781981421339\n",
      "test_precision: 0.0108182291754002\n",
      "test_recall: 0.0064010788746646135\n",
      "test_f1: 0.0056401776854568715\n",
      "test_f2: 0.004905377595533144\n",
      "test_roc_auc: 0.0036716934387874722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def specificity_scorer(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'specificity': make_scorer(specificity_scorer),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'f2': make_scorer(lambda y_true, y_pred: fbeta_score(y_true, y_pred, beta=2)),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_validate(estimator=clf_FULL, X=X_imputed_train, y=y_imputed_train, \n",
    "                cv=cv,scoring=scoring, n_jobs = 1, verbose = 2)\n",
    "print(\"CV Mean Metrics:\")\n",
    "for metric, values in results.items():\n",
    "    mean_value = np.mean(values)\n",
    "    print(f\"{metric}: {mean_value}\")\n",
    "\n",
    "print(\"\\nCV Standard Deviations:\")\n",
    "for metric, values in results.items():\n",
    "    std_value = np.std(values)\n",
    "    print(f\"{metric}: {std_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7dbfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
